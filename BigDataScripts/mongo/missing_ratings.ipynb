{"cells":[{"cell_type":"code","execution_count":null,"id":"121e8544","metadata":{"id":"121e8544","outputId":"ba64cf44-d6c4-46aa-e3f8-8432854bd250"},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/26 16:24:18 WARN Utils: Your hostname, DSaDBA resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n","23/06/26 16:24:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/06/26 16:24:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["import findspark\n","# Locate the Spark installation\n","findspark.init()\n","\n","import pyspark\n","from pyspark import StorageLevel\n","from pyspark.sql.functions import col\n","from pyspark.sql.functions import regexp_replace\n","from pyspark.sql import *\n","\n","spark = SparkSession.builder\\\n","        .appName(\"MissingRatings\")\\\n","        .master(\"local[*]\")\\\n","        .config(\"spark.driver.memory\", \"4g\")\\\n","        .config(\"spark.executor.memory\", \"5g\")\\\n","        .config(\"spark.storage.memoryFraction\", \"0.5\")\\\n","        .config(\"spark.shuffle.memoryFraction\", \"0.5\")\\\n","        .config(\"spark.driver.maxResultSize\", \"0\")\\\n","        .getOrCreate()"]},{"cell_type":"code","execution_count":null,"id":"05db3d1b","metadata":{"id":"05db3d1b"},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, ArrayType, StringType, LongType\n","\n","# Define the schema\n","schema = StructType([\n","    StructField('movie', StringType(), True),\n","    StructField('rating', StringType(), True),\n","    StructField('genre', StringType(), True),\n","    StructField('review_date', StringType(),True),\n","    StructField('review_detail', StringType(), True),\n","    StructField('review_id', StringType(), True),\n","    StructField('review_summary', StringType(), True),\n","    StructField('reviewer', StringType(), True),\n","    StructField('spoiler_tag', LongType(), True),\n","    StructField('helpful_upvotes', LongType(), True),\n","    StructField('helpful_total', LongType(), True)])"]},{"cell_type":"code","execution_count":null,"id":"be6c2fa1","metadata":{"id":"be6c2fa1"},"outputs":[],"source":["# Read the file to filter from the HDFS\n","df = spark.read.csv('hdfs://localhost:54310/user/reviews/mr_data_3456', schema=schema, sep=\"\\t\")"]},{"cell_type":"code","execution_count":null,"id":"4e635c12","metadata":{"id":"4e635c12"},"outputs":[],"source":["# Keep only the reviews which have no rating\n","filtered_df = df[~df['rating'].isNotNull()]\n","filtered_df = filtered_df[filtered_df['movie'].isNotNull()]\n","filtered_df.limit(5).toPandas()"]},{"cell_type":"code","execution_count":null,"id":"340c04ba","metadata":{"id":"340c04ba"},"outputs":[],"source":["# Randomly subsample the data to work on a manageable sample in the sandox environment\n","number_of_samples = 10000\n","sample_df = filtered_df.sample(withReplacement=False, fraction=number_of_samples/filtered_df.count())"]},{"cell_type":"code","execution_count":null,"id":"0eb2fdf3","metadata":{"id":"0eb2fdf3"},"outputs":[],"source":["import pymongo\n","\n","# Connect to the local MongoDB instance and select the database used as repository for the dataset\n","mongo = pymongo.MongoClient()\n","mongo_db = mongo.project\n","# Clear the content of the reviews collection\n","mongo_db.noRatings.delete_many({})"]},{"cell_type":"code","execution_count":null,"id":"27b4cbdd","metadata":{"id":"27b4cbdd"},"outputs":[],"source":["# Get a dict representation of the DataFrame containing the sample\n","dict = sample_df.toPandas().to_dict(orient='records')\n","# Insert the reviews in the collection of the project MongoDB database\n","mongo_db.noRatings.insert_many(dict);"]},{"cell_type":"code","execution_count":null,"id":"ac6e6490","metadata":{"id":"ac6e6490"},"outputs":[],"source":["# Close the connection to the local MongoDB instance\n","mongo.close()\n","\n","# Stop the Spark context underlying the Spark session\n","spark.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}